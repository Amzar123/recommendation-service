from mlxtend.preprocessing import TransactionEncoder
import pandas as pd


from src.service.nlg_core import NLGCore


class DataPreProcessing:
    """
    Class for handling data preprocessing
    """

    def __init__(self) -> None:
        self.obj_nlg = NLGCore()

    def recommend_materials(self, student_data, rules, competency_to_material, material_details):
        """
        Generate recommendation materials for a single student.
        """
        student_name = student_data["name"]
        competencies = set(student_data["competencies"])
        recommendations = set()

        # Iterate through each association rule
        for idx, rule in rules.iterrows():
            antecedents = set(rule['antecedents'])
            consequents = set(rule['consequents'])

            uncompeten = list(set(competency_to_material.keys()) - competencies)

            # Check if the student is missing any antecedents
            missing_antecedents = antecedents - set(uncompeten)

            if missing_antecedents:
                # Recommend all materials related to the missing antecedents
                for antecedent in missing_antecedents:
                    if antecedent in competency_to_material:
                        recommendations.add(competency_to_material[antecedent])

        # Map student to recommended materials with details
        student_material_details = []
        for material in recommendations:
            if material in material_details:
                student_material_details.extend(material_details[material])

        student_recommendations = {student_name: self.obj_nlg.generate_text(student_material_details)}
        return student_recommendations

    def transform_result_to_biner(self, test_result, questions):
        """
        This function is to transform result to biner data
        """
        question_list = [
            "soal 1",
            "soal 2",
            "soal 3",
            "soal 4",
            "soal 5",
            "soal 6",
            "soal 7",
            "soal 8",
            "soal 9",
            "soal 10",
            "soal 11",
            "soal 12",
            "soal 13",
            "soal 14",
            "soal 15",
            "soal 16",
            "soal 17",
            "soal 18",
            "soal 19",
            "soal 20",
            "soal 21",
            "soal 22",
            "soal 23",
            "soal 24",
            "soal 25",
            "soal 26",
            "soal 27",
            "soal 28",
            "soal 29",
            "soal 30"
        ]
        index = 0
        for q in question_list:
            for i in range(len(test_result)):
                if questions["key"][index] == "":
                    test_result[q][i] = 0
                elif test_result[q][i] == questions["key"][index]:
                    test_result[q][i] = 1
                else:
                    test_result[q][i] = 0
            index += 1

        return test_result

    def mapping_student_competency(
            self,
            transformed_data,
            df_mapping_question_comp):
        '''
        Implement to map student wrong answers with competencies.
        '''

        # Convert the first column (score) to a separate series and drop it
        # from the DataFrame
        scores = transformed_data.iloc[:, 0]
        student_answers = transformed_data.iloc[:, 1:]

        # Competencies list
        lib = [
            "main_verbs",
            "tense",
            "infinitives",
            "passives",
            "have_+_participle",
            "auxiliary_verbs",
            "pronouns",
            "nouns",
            "determiners",
            "other_adjectives",
            "prepositions",
            "conjunctions",
            "subject_verb_agreement"
        ]

        student_list = []

        for idx, row in student_answers.iterrows():
            student = {"name": f"student_{idx+1}", "competencies": set()}

            for question_index, answer in row.items():
                if answer == 0:  # If the answer is wrong
                    try:
                        # Strip any leading or trailing spaces
                        question_index = question_index.strip()
                        # Extract the question number
                        question_num = int(question_index.split(' ')[-1]) - 1
                        if question_num < len(df_mapping_question_comp):
                            for comp in lib:
                                if df_mapping_question_comp.at[question_num, comp]:
                                    student["competencies"].add(comp)
                    except (ValueError, IndexError) as e:
                        print(
                            f"Skipping invalid question index '{question_index}' for student {idx+1}: {e}")

            # Convert the set to a list for JSON serialization or other
            # processing
            student["competencies"] = list(student["competencies"])
            student_list.append(student)
            print(student)

        return student_list

    def generate_final_dataset(self, mapped_data):
        """
        This function can generate final dataset
        """
        final_dataset = []
        for element in mapped_data:
            final_dataset.append(element['competencies'])
        return final_dataset

    def data_transformation(self, final_dataset):
        """
        This function is to transform data after final data set was generated
        """
        tr = TransactionEncoder()
        tr_ary = tr.fit(final_dataset).transform(final_dataset)
        df_incorrect = pd.DataFrame(tr_ary, columns=tr.columns_)
        return df_incorrect
